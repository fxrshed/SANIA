{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farshed.abdukhakimov/.conda/envs/psps/bin/python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "farshed.abdukhakimov\n",
      "cn-08\n",
      "/home/farshed.abdukhakimov/projects/sania\n"
     ]
    }
   ],
   "source": [
    "!which python \n",
    "!whoami \n",
    "!hostname\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farshed.abdukhakimov/.conda/envs/psps/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import experiments.loss_functions as lf\n",
    "from experiments.utils import get_dataset\n",
    "\n",
    "# import scipy\n",
    "import optuna \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "dataset_name = \"news20/news20.binary.bz2\"\n",
    "batch_size = 128\n",
    "\n",
    "datasets_path = os.getenv(\"LIBSVM_DIR\")\n",
    "trainX, trainY = load_svmlight_file(f\"{datasets_path}/{dataset_name}\")\n",
    "\n",
    "train_data = torch.tensor(trainX.toarray())\n",
    "train_target = torch.tensor(trainY)\n",
    "\n",
    "train_load = TensorDataset(train_data, train_target)\n",
    "train_dataloader = DataLoader(train_load, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train = train_data, train_target, train_dataloader\n",
    "\n",
    "\n",
    "loss_function = lf.logreg\n",
    "loss_grad = lf.grad_logreg\n",
    "loss_hessian = lf.hess_logreg\n",
    "\n",
    "\n",
    "# if loss_function == lf.logreg:\n",
    "#     train_target[train_target == train_target.unique()[0]] = torch.tensor(-1.0, dtype=torch.get_default_dtype())\n",
    "#     train_target[train_target == train_target.unique()[1]] = torch.tensor(1.0, dtype=torch.get_default_dtype())\n",
    "#     assert torch.equal(train_target.unique(), torch.tensor([-1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 178560)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350000, 254)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
